{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ae0fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd3b470c07c443195caaf8b67dc9f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting and de-quantizing GGUF tensors...:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import youtokentome as yttm\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"JetBrains_model\", gguf_file=\"flcc.model\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ac7d3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [4, 8251, 5588, 4529, 142, 4, 845, 1907, 6467, 95, 12885, 315, 9499, 34, 6122, 699, 2772, 4, 1887, 6289, 14605, 4]\n",
      "Decoded back: \n",
      "public class HelloWorld {\n",
      "    public static void main(String[] args) {\n",
      "        System.out.\n",
      "\n",
      "Raw output tokens: [4, 8251, 5588, 4529, 142, 4, 845, 1907, 6467, 95, 12885, 315, 9499, 34, 6122, 699, 2772, 4, 1887, 6289, 14605, 4, 8380, 2112, 5588, 136, 4529, 5498, 60, 4, 36, 421, 545, 210, 4, 434, 1380, 132, 12109, 1921, 918, 143]\n",
      "Input prompt:\n",
      "public class HelloWorld {\n",
      "    public static void main(String[] args) {\n",
      "        System.out.\n",
      "\n",
      "Generated completion:\n",
      "        System.out.            println(\"Hello, World!\");\n",
      "}   }\")\n",
      "private val root: Element = VectorElement()\n"
     ]
    }
   ],
   "source": [
    "prefix_code = \"\"\"\n",
    "public class HelloWorld {\n",
    "    public static void main(String[] args) {\n",
    "        System.out.\n",
    "\"\"\"\n",
    "\n",
    "bpe = yttm.BPE(model=\"JetBrains_model/flcc.bpe\")\n",
    "\n",
    "tokens = bpe.encode(prefix_code, output_type=yttm.OutputType.ID)\n",
    "\n",
    "# Print tokenization to verify\n",
    "print(f\"Token IDs: {tokens}\")\n",
    "print(f\"Decoded back: {bpe.decode([tokens])[0]}\")\n",
    "\n",
    "# Convert to tensor\n",
    "input_ids = torch.tensor([tokens]).to(model.device)\n",
    "attention_mask = torch.ones_like(input_ids).to(model.device)\n",
    "\n",
    "# Generate completions\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=20,  # Controls how many new tokens to generate\n",
    "        do_sample=True,     # Use sampling\n",
    "        top_p=0.95,         # Nucleus sampling parameter\n",
    "        top_k=40,           # Limit to top 50 tokens at each step\n",
    "        temperature=0.6,    # Controls randomness (lower is more deterministic)\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=model.config.eos_token_id,  # Set padding token to EOS token\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "# Print the raw output to understand what's happening\n",
    "print(\"Raw output tokens:\", outputs[0].tolist())\n",
    "\n",
    "# Get the generated content after the prompt\n",
    "original_length = len(tokens)\n",
    "generated_tokens = outputs[0][original_length:].tolist()\n",
    "\n",
    "# Decode only the newly generated tokens\n",
    "completion = bpe.decode([generated_tokens])[0]\n",
    "\n",
    "# Format the output\n",
    "print(\"Input prompt:\")\n",
    "print(prefix_code.strip())\n",
    "print(\"\\nGenerated completion:\")\n",
    "print(f\"        System.out.{completion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
